{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprocessing procedure for Las Campanas Observatory Swope data using BANZAI-Imaging\n",
    "## Matt Daily"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up relevant runtime configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:ConnectionError(MaxRetryError(\"HTTPConnectionPool(host='scheduler-dev.lco.gtn', port=80): Max retries exceeded with url: /api/version (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x11dae39d0>: Failed to establish a new connection: [Errno 8] nodename nor servname provided, or not known'))\"))\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from banzai.calibrations import make_master_calibrations\n",
    "from banzai import settings\n",
    "from banzai import dbs\n",
    "from banzai.utils.stage_utils import run_pipeline_stages\n",
    "from banzai.logs import set_log_level\n",
    "import banzai.main\n",
    "\n",
    "import pkg_resources\n",
    "import requests\n",
    "from astropy.io import fits\n",
    "\n",
    "\n",
    "set_log_level('DEBUG')\n",
    "logger = logging.getLogger('banzai')\n",
    "\n",
    "os.environ['OPENTSDB_PYTHON_METRICS_TEST_MODE'] = 'True'\n",
    "os.environ['DB_ADDRESS'] = 'sqlite:///test.db'\n",
    "\n",
    "settings.processed_path= os.path.join(os.getcwd(), 'test_data')\n",
    "settings.fpack=True\n",
    "settings.db_address = os.environ['DB_ADDRESS']\n",
    "settings.no_bpm = True\n",
    "settings.reduction_level = 91\n",
    "\n",
    "# set up the context object.\n",
    "context = banzai.main.parse_args(settings, parse_system_args=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the data from the directory and combine it into MEFs\n",
    "This branch of BANZAI expects that each amplifier have an extension in an MEF. BANZAI can then do the work of stitching them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "raw_data_dir = os.path.join(os.getcwd(), 'swope_data', 'raw')\n",
    "mef_combined_data_dir = os.path.join(os.getcwd(), 'swope_data', 'mef_combined')\n",
    "\n",
    "# TODO: Need to be able to parse filenames and split them into MEFs as necessary - this will need an outer loop.\n",
    "prefix_set = set()\n",
    "for file_path in glob(os.path.join(raw_data_dir, '*.fits.fz')):\n",
    "    # extract the unique prefixes from the raw data directory\n",
    "    prefix_set.add(re.sub('c\\d', '', file_path))\n",
    "\n",
    "# now create MEFs from the groupings!\n",
    "for prefix in prefix_set:\n",
    "    filepaths = [prefix.replace('.fits.fz', f'c{i}.fits.fz') for i in range(1,5)]\n",
    "\n",
    "    image_hdus = fits.HDUList([fits.PrimaryHDU()])\n",
    "    for path in filepaths:\n",
    "        image_hdus.append(fits.open(path)['COMPRESSED_IMAGE'])\n",
    "\n",
    "    # Now do some munging of the headers.\n",
    "    # 1 is top right, rotate 90 counterclockwise and invert x (x -> -y, y-> -x)\n",
    "    image_hdus[1].data = image_hdus[1].data.T[::-1, ::-1]\n",
    "    image_hdus[1].header['DATASEC'] = '[129:2184,129:2176]'\n",
    "    image_hdus[1].header['BIASSEC'] = '[1:128,1:2176]'\n",
    "    image_hdus[1].header['DETSEC'] = '[2057:4112,2049:4096]'\n",
    "    image_hdus[1].header.pop('TRIMSEC')\n",
    "\n",
    "    # 2 is bottom left rotate 90 clockwise and invert x (y -> x x -> y)\n",
    "    image_hdus[2].data = image_hdus[2].data.T\n",
    "    image_hdus[2].header['DATASEC'] = '[1:2056,1:2048]'\n",
    "    image_hdus[2].header['BIASSEC'] ='[2057:2084,1:2176]'\n",
    "    image_hdus[2].header['DETSEC'] = '[1:2056,1:2048]'\n",
    "    image_hdus[2].header.pop('TRIMSEC')\n",
    "\n",
    "    # 3 bottom right rotate 90 counterclockwise (x-> -y, y - > x)\n",
    "    image_hdus[3].data = image_hdus[3].data.T[:, ::-1]\n",
    "    image_hdus[3].header['DATASEC'] = '[129:2184,1:2048]'\n",
    "    image_hdus[3].header['BIASSEC'] ='[1:129,1:2176]'\n",
    "    image_hdus[3].header['DETSEC'] = '[2057:4112,1:2048]'\n",
    "    image_hdus[3].header.pop('TRIMSEC')\n",
    "\n",
    "    # 4 is top left 270 deg  counterclockwise (x -> y, y->-x)\n",
    "    image_hdus[4].data = image_hdus[4].data.T[::-1, :]\n",
    "    image_hdus[4].header['DATASEC'] = '[1:2056,129:2176]'\n",
    "    image_hdus[4].header['BIASSEC'] ='[2057:2184,1:2176]'\n",
    "    image_hdus[4].header['DETSEC'] = '[1:2056, 2049:4096]'\n",
    "    image_hdus[4].header.pop('TRIMSEC')\n",
    "\n",
    "    # Copy all overlapping values into the main header\n",
    "    for i in image_hdus[1].header:\n",
    "        if i == 'COMMENT' or len(i) == 0:\n",
    "            continue\n",
    "        if image_hdus[2].header.get(i) == image_hdus[1].header.get(i):\n",
    "            image_hdus[0].header[i] = image_hdus[1].header[i]\n",
    "\n",
    "    image_hdus[0].header['TRIMSEC'] = '[1:4112,1:4096]'\n",
    "\n",
    "    for i in range(1,5):\n",
    "        image_hdus[i].header['RDNOISE'] = image_hdus[i].header['ENOISE']\n",
    "        image_hdus[i].header['GAIN']  = image_hdus[i].header['EGAIN'] \n",
    "\n",
    "    # now create an HDUList and a unique filename to store the data in\n",
    "    hdu_list = fits.HDUList(image_hdus)\n",
    "    filename = f'{image_hdus[1].header[\"FILENAME\"][:-2]}-{image_hdus[1].header[\"UT-DATE\"].replace(\"-\", \"\")}-combined.fits.fz'\n",
    "    with open(os.path.join(mef_combined_data_dir, filename), 'wb') as f:\n",
    "        hdu_list.writeto(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'banzai_create_db --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_site --site LCO --latitude -29.08300 --longitude -70.698005 --elevation 2280 --timezone -4 --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_instrument --site LCO --camera Direct/4Kx4K-4 --name Direct/4Kx4K-4 --instrument-type swope-imager --db-address={os.environ[\"DB_ADDRESS\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai.lco import LCOFrameFactory\n",
    "\n",
    "frame_factory = LCOFrameFactory()\n",
    "frame = frame_factory.open({'path': os.path.join(mef_combined_data_dir, filename) }, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<banzai.utils.image_utils.Section at 0x131b387c0>,\n",
       " <banzai.utils.image_utils.Section at 0x131b56d60>,\n",
       " <banzai.utils.image_utils.Section at 0x131b22490>,\n",
       " <banzai.utils.image_utils.Section at 0x131b6b5b0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ccd.detector_section for ccd in frame.ccd_hdus]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now stitch the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-20 10:15:45.195     INFO:          mosaic: Mosaicing image | {\"filename\": \"ccd1144-20220925-combined.fits.fz\", \"site\": \"LCO\", \"instrument\": \"Direct/4Kx4K-4\", \"epoch\": \"20220925\", \"request_num\": null, \"obstype\": \"Object\", \"filter\": \"r\", \"processName\": \"MainProcess\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:banzai:Mosaicing image | {\"filename\": \"ccd1144-20220925-combined.fits.fz\", \"site\": \"LCO\", \"instrument\": \"Direct/4Kx4K-4\", \"epoch\": \"20220925\", \"request_num\": null, \"obstype\": \"Object\", \"filter\": \"r\", \"processName\": \"MainProcess\"}\n"
     ]
    }
   ],
   "source": [
    "from banzai.mosaic import MosaicCreator\n",
    "\n",
    "mosaic_stage = MosaicCreator(context)\n",
    "image = mosaic_stage.do_stage(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_image = fits.HDUList([fits.PrimaryHDU(), fits.ImageHDU(image.data, image.meta)])\n",
    "with open(os.path.join('/Users/mdaily/Documents/banzai/notebooks/swope_data/processed', filename.replace('combined', 'mosaicked-intermediate')), 'wb') as f:\n",
    "    intermediate_image.writeto(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
