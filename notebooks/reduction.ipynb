{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reprocessing procedure for Las Campanas Observatory Swope data using BANZAI-Imaging\n",
    "## Matt Daily"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up relevant runtime configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from banzai.calibrations import make_master_calibrations\n",
    "from banzai import settings\n",
    "from banzai import dbs\n",
    "from banzai.utils.stage_utils import run_pipeline_stages\n",
    "from banzai.logs import set_log_level\n",
    "import banzai.main\n",
    "\n",
    "import pkg_resources\n",
    "import requests\n",
    "from astropy.io import fits\n",
    "\n",
    "\n",
    "set_log_level('DEBUG')\n",
    "logger = logging.getLogger('banzai')\n",
    "\n",
    "os.environ['OPENTSDB_PYTHON_METRICS_TEST_MODE'] = 'True'\n",
    "os.environ['DB_ADDRESS'] = 'sqlite:///test.db'\n",
    "\n",
    "settings.processed_path= os.path.join(os.getcwd(), 'test_data')\n",
    "settings.fpack=True\n",
    "settings.db_address = os.environ['DB_ADDRESS']\n",
    "settings.no_bpm = True\n",
    "settings.reduction_level = 91\n",
    "\n",
    "# set up the context object.\n",
    "context = banzai.main.parse_args(settings, parse_system_args=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take the data from the directory and combine it into MEFs\n",
    "This branch of BANZAI expects that each amplifier have an extension in an MEF. BANZAI can then do the work of stitching them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dir = os.path.join(os.getcwd(), 'swope_data', 'raw')\n",
    "mef_combined_data_dir = os.path.join(os.getcwd(), 'swope_data', 'mef_combined')\n",
    "processed_data_dir = os.path.join(os.getcwd(), 'swope_data', 'processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_set = set()\n",
    "for file_path in glob(os.path.join(raw_data_dir, '*.fits.fz')):\n",
    "    # extract the unique prefixes from the raw data directory\n",
    "    prefix_set.add(re.sub('c\\d', '', file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create MEFs from the groupings!\n",
    "for prefix in prefix_set:\n",
    "    filepaths = [prefix.replace('.fits.fz', f'c{i}.fits.fz') for i in range(1,5)]\n",
    "\n",
    "    image_hdus = fits.HDUList([fits.PrimaryHDU()])\n",
    "    for path in filepaths:\n",
    "        image_hdus.append(fits.open(path)['COMPRESSED_IMAGE'])\n",
    "\n",
    "    # Now do some munging of the headers.\n",
    "    # 1 is top right, rotate 90 counterclockwise and invert x (x -> -y, y-> -x)\n",
    "    image_hdus[1].data = image_hdus[1].data.T[::-1, ::-1]\n",
    "    image_hdus[1].header['DATASEC'] = '[129:2184,129:2176]'\n",
    "    image_hdus[1].header['BIASSEC'] = '[1:128,1:2176]'\n",
    "    image_hdus[1].header['DETSEC'] = '[2057:4112,2049:4096]'\n",
    "    image_hdus[1].header.pop('TRIMSEC')\n",
    "\n",
    "    # 2 is bottom left rotate 90 clockwise and invert x (y -> x x -> y)\n",
    "    image_hdus[2].data = image_hdus[2].data.T\n",
    "    image_hdus[2].header['DATASEC'] = '[1:2056,1:2048]'\n",
    "    image_hdus[2].header['BIASSEC'] ='[2057:2084,1:2176]'\n",
    "    image_hdus[2].header['DETSEC'] = '[1:2056,1:2048]'\n",
    "    image_hdus[2].header.pop('TRIMSEC')\n",
    "\n",
    "    # 3 bottom right rotate 90 counterclockwise (x-> -y, y - > x)\n",
    "    image_hdus[3].data = image_hdus[3].data.T[:, ::-1]\n",
    "    image_hdus[3].header['DATASEC'] = '[129:2184,1:2048]'\n",
    "    image_hdus[3].header['BIASSEC'] ='[1:129,1:2176]'\n",
    "    image_hdus[3].header['DETSEC'] = '[2057:4112,1:2048]'\n",
    "    image_hdus[3].header.pop('TRIMSEC')\n",
    "\n",
    "    # 4 is top left 270 deg  counterclockwise (x -> y, y->-x)\n",
    "    image_hdus[4].data = image_hdus[4].data.T[::-1, :]\n",
    "    image_hdus[4].header['DATASEC'] = '[1:2056,129:2176]'\n",
    "    image_hdus[4].header['BIASSEC'] ='[2057:2184,1:2176]'\n",
    "    image_hdus[4].header['DETSEC'] = '[1:2056, 2049:4096]'\n",
    "    image_hdus[4].header.pop('TRIMSEC')\n",
    "\n",
    "    # Copy all overlapping values into the main header\n",
    "    for i in image_hdus[1].header:\n",
    "        if i == 'COMMENT' or len(i) == 0:\n",
    "            continue\n",
    "        if image_hdus[2].header.get(i) == image_hdus[1].header.get(i):\n",
    "            image_hdus[0].header[i] = image_hdus[1].header[i]\n",
    "\n",
    "    image_hdus[0].header['TRIMSEC'] = '[1:4112,1:4096]'\n",
    "\n",
    "    for i in range(1,5):\n",
    "        image_hdus[i].header['RDNOISE'] = image_hdus[i].header['ENOISE']\n",
    "        image_hdus[i].header['GAIN']  = image_hdus[i].header['EGAIN'] \n",
    "\n",
    "    # now create an HDUList and a unique filename to store the data in\n",
    "    filename_suffix_obstype_mapping = {'Bias': 'b00',\n",
    "                                       'Flat': 'f00',\n",
    "                                       'Object': 'e00'}\n",
    "    hdu_list = fits.HDUList(image_hdus)\n",
    "    filename = f'{image_hdus[1].header[\"FILENAME\"][:-2]}-{image_hdus[1].header[\"UT-DATE\"].replace(\"-\", \"\")}-{filename_suffix_obstype_mapping[image_hdus[1].header[\"EXPTYPE\"]]}.fits.fz'\n",
    "    hdu_list.writeto(os.path.join(mef_combined_data_dir, filename), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f'banzai_create_db --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_site --site LCO --latitude -29.08300 --longitude -70.698005 --elevation 2280 --timezone -4 --db-address={os.environ[\"DB_ADDRESS\"]}')\n",
    "os.system(f'banzai_add_instrument --site LCO --camera Direct/4Kx4K-4 --name Direct/4Kx4K-4 --instrument-type swope-imager --db-address={os.environ[\"DB_ADDRESS\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument = dbs.get_instruments_at_site('LCO', settings.db_address)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_files = glob(os.path.join(mef_combined_data_dir, '*b00*'))\n",
    "for bias_file in bias_files:\n",
    "    run_pipeline_stages([{'path': bias_file}], context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_frames_as_good(filenames):\n",
    "    for filename in glob(f'test_data/LCO/Direct/4Kx4K-4/20220925/processed/{filenames}'):\n",
    "        dbs.mark_frame(os.path.basename(filename), \"good\", db_address=os.environ['DB_ADDRESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_frames_as_good('*b91*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_master_calibrations(instrument, 'Bias', '2022-09-20', '2022-09-30', context)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now stitch the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from banzai.mosaic import MosaicCreator\n",
    "\n",
    "mosaic_stage = Mos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_image = fits.HDUList([fits.PrimaryHDU(), fits.ImageHDU(image.data, image.meta)])\n",
    "with open(os.path.join('/Users/mdaily/Documents/banzai/notebooks/swope_data/processed', filename.replace('combined', 'mosaicked-intermediate')), 'wb') as f:\n",
    "    intermediate_image.writeto(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
